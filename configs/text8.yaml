# DATASET config

root_path:
  desc: Path to the prepared data
  value: data/text8

# EXPERIMENT CONFIG

experiment_name:
  desc: Name of the WandB experiment
  value: experiment_text8
log_interval:
  desc: Number of batches to report on
  value: 1000

# TRAINING CONFIG

seed:
  desc: Seed for reproducability
  value : 32
save_best_model: 
  desc: Whether to save the best model seen during training
  value: True
save_final_model:
  desc: Whether to save the final model after training is complete
  value: True

batch_size: 
  value: 128
epochs:
  value: 1000
lr: 
  value: 0.003
momentum:
  value: 0.99
sequence_length:
  desc: The maximum length of sequence fed to the model. Used to split the data and to define positional encodings.
  value: 512

# MODEL CONFIG

dropout:
  desc: Percentage of weights to disconnect during training for regularisation.
  value : 0.2
hidden_size:
  desc: Size of each embedding in the model.
  value: 512
inner_linear:
  desc: Size of inner layer in feedforward layers.
  value: 2048
n_layers:
  desc: Number of layers in the encoder.
  value: 12
