name: 'gpt2_lm_head_model'

model_kwargs: {
  "n_layer": 2, 
  "n_head": 4,
  "n_embd": 128, 
  "n_positions": 256,
  "n_inner": 512,
}
